{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.get_pose_landmark import get_pose_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"videos/jab_tutorial.mp4\"\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "get_pose_landmarks(video, \"csvs/jab_tutorial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features\n",
    "\n",
    "def extract_features(landmarks):\n",
    "    left_shoulder = [landmarks[11].x, landmarks[11].y]\n",
    "    left_elbow = [landmarks[13].x, landmarks[13].y]\n",
    "    left_wrist = [landmarks[15].x, landmarks[15].y]\n",
    "\n",
    "    right_shoulder = [landmarks[12].x, landmarks[12].y]\n",
    "    right_elbow = [landmarks[14].x, landmarks[14].y]\n",
    "    right_wrist = [landmarks[16].x, landmarks[16].y]\n",
    "\n",
    "    left_arm_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "    right_arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "    return [left_arm_angle, right_arm_angle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_training_data(data_directory):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    label_mapping = {\n",
    "        \"jab\": 0,\n",
    "        \"cross\": 1,\n",
    "        \"hook/front\": 2,\n",
    "        \"hook/rear\": 3,\n",
    "        \"uppercut/front\": 4,\n",
    "        \"uppercut/rear\": 5,\n",
    "    }\n",
    "\n",
    "    for subdir in os.listdir(data_directory):\n",
    "        subdir_path = os.path.join(data_directory, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            label = label_mapping[subdir]\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                if filename.endswith(\".npy\"):\n",
    "                    file_path = os.path.join(subdir_path, filename)\n",
    "                    features_data = np.load(file_path)\n",
    "                    features.append(features_data)\n",
    "                    labels.append(label)\n",
    "\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "data_directory = \"videos\"\n",
    "X, y = load_training_data(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_training_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "accuracy = classifier.score(X_test, y_test)\n",
    "print(f\"Classifier accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_punches(cap, classifier):\n",
    "    with mp_pose.Pose(\n",
    "        min_detection_confidence=0.5, min_tracking_confidence=0.5\n",
    "    ) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, image = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(image_rgb)\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            if landmarks:\n",
    "                punch_type = classifier.predict([extracted_features])[0]\n",
    "                cv2.putText(\n",
    "                    image,\n",
    "                    f\"Punch: {punch_type}\",\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS\n",
    "                )\n",
    "\n",
    "            cv2.imshow(\"Punch Recognition\", image)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
